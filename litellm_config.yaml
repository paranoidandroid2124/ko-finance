# SSoT(3, 4) 기반 LiteLLM 설정 파일
# - 기본 모델: Gemini Flash-Lite (gemini_flash_lite)
# - 품질 승격 모델: GPT-5 (gpt-5-chat)
# - 로컬 감성 분석 모델: 주석 처리 (vllm-sentiment)

model_list:
  - model_name: gemini_flash_lite  # Default fast model for summarization
    litellm_params:
      model: "gemini/gemini-2.5-flash-lite-preview-09-2025"
      api_key: ${GEMINI_API_KEY}

  - model_name: gpt-5-chat  # High-quality fallback model
    litellm_params:
      model: "openai/gpt-5-chat-latest"
      api_key: ${OPENAI_API_KEY}

  - model_name: gpt-4o-mini  # Guard judge model for compliance checks
    litellm_params:
      model: "openai/gpt-4o-mini"
      api_key: ${OPENAI_API_KEY}

  # - model_name: qwen14b_lora_local
  #   litellm_params:
  #     model: "qwen/Qwen1.5-14B-Chat-AWQ"
  #     api_base: "http://vllm-sentiment:8001/v1"
  #     api_key: "EMPTY"

litellm_settings:
  # 디버깅 및 로깅 레벨 설정
  set_verbose: True
  # SSoT(8) Langfuse 연동을 위한 설정 (추후 활성화)
  # success_callback: ["langfuse"]
  # failure_callback: ["langfuse"]

router_settings:
    enable_health_check: True
    enable_prometheus: True
