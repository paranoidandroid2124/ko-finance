# Nuvien LiteLLM configuration
# - Default model: Gemini Flash-Lite (baseline)
# - Fallback model: GPT-5 (fallback_model)
# - Guardrail judge model: GPT-4o mini (judge_model)
# Provide GEMINI_API_KEY / OPENAI_API_KEY via environment variables before running.

model_list:
  - model_name: baseline  # Default fast model for summarization
    litellm_params:
      model: "gemini/gemini-2.5-flash-lite-preview-09-2025"
      api_key: ${GEMINI_API_KEY}

  - model_name: fallback_model  # High-quality fallback model
    litellm_params:
      model: "openai/gpt-5-chat-latest"
      api_key: ${OPENAI_API_KEY}

  - model_name: judge_model  # Guard judge model for compliance checks
    litellm_params:
      model: "openai/gpt-4o-mini"
      api_key: ${OPENAI_API_KEY}

litellm_settings:
  set_verbose: True
  cache: true

router_settings:
  enable_health_check: True
  enable_prometheus: True
