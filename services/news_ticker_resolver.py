"\"\"\"Heuristics for inferring equity tickers from news articles.\"\"\""

from __future__ import annotations

import re
import time
from dataclasses import dataclass
from typing import Iterable, List, Optional, Sequence, Tuple

from sqlalchemy.orm import Session

from models.security_metadata import SecurityMetadata

_CACHE_TTL_SECONDS = 60 * 60  # 1 hour
_NUMERIC_TICKER_PATTERN = re.compile(r"\b\d{6}\b")
_NON_ALPHANUM = re.compile(r"[^0-9a-z가-힣]")


@dataclass
class _TickerCache:
    loaded_at: float = 0.0
    corp_aliases: Sequence[Tuple[str, str]] = ()
    ticker_values: Sequence[str] = ()

    def expired(self) -> bool:
        return (time.time() - self.loaded_at) > _CACHE_TTL_SECONDS


_cache = _TickerCache()


def _normalize_alias(value: Optional[str]) -> str:
    if not value:
        return ""
    normalized = value.lower()
    normalized = normalized.replace("주식회사", "")
    normalized = normalized.replace("(주)", "")
    normalized = normalized.replace("㈜", "")
    normalized = _NON_ALPHANUM.sub("", normalized)
    return normalized.strip()


def _generate_aliases(name: Optional[str]) -> Iterable[str]:
    if not name:
        return []
    raw = name.strip()
    variants = {raw}
    cleaned = raw.replace("(주)", "").replace("㈜", "").strip()
    if cleaned:
        variants.add(cleaned)
    without_spaces = raw.replace(" ", "")
    if without_spaces:
        variants.add(without_spaces)
    without_spaces_cleaned = cleaned.replace(" ", "")
    if without_spaces_cleaned:
        variants.add(without_spaces_cleaned)
    return variants


def _refresh_cache(session: Session) -> None:
    rows: List[Tuple[str, Optional[str]]] = (
        session.query(SecurityMetadata.ticker, SecurityMetadata.corp_name)
        .filter(SecurityMetadata.ticker.isnot(None))
        .all()
    )
    aliases: List[Tuple[str, str]] = []
    tickers: List[str] = []
    for ticker, corp_name in rows:
        if not ticker:
            continue
        normalized_ticker = ticker.strip().upper()
        tickers.append(normalized_ticker)
        for alias in _generate_aliases(corp_name):
            normalized_alias = _normalize_alias(alias)
            if normalized_alias:
                aliases.append((normalized_alias, normalized_ticker))
    _cache.corp_aliases = aliases
    _cache.ticker_values = tickers
    _cache.loaded_at = time.time()


def _ensure_cache(session: Session) -> None:
    if not _cache.corp_aliases or _cache.expired():
        _refresh_cache(session)


def _match_numeric_ticker(text: str, tickers: Iterable[str]) -> Optional[str]:
    if not text:
        return None
    tickers_set = set(tickers)
    for match in _NUMERIC_TICKER_PATTERN.findall(text):
        candidate = match.strip().upper()
        if candidate in tickers_set:
            return candidate
    return None


def resolve_news_ticker(
    session: Session,
    *,
    headline: Optional[str] = None,
    summary: Optional[str] = None,
    body: Optional[str] = None,
    topics: Optional[Iterable[str]] = None,
) -> Optional[str]:
    """Infer a ticker from an article's content or topics.

    Parameters
    ----------
    session:
        Database session used to load cached security metadata.
    headline/summary/body:
        Textual content to inspect for ticker references or company names.
    topics:
        Optional topic keywords generated by the LLM analysis.
    """

    combined_parts: List[str] = []
    for value in (headline, summary, body):
        if value:
            combined_parts.append(value)
    if topics:
        combined_parts.extend(topic for topic in topics if topic)
    combined_text = " ".join(combined_parts)
    if not combined_text.strip():
        return None

    _ensure_cache(session)

    numeric_match = _match_numeric_ticker(combined_text, _cache.ticker_values)
    if numeric_match:
        return numeric_match

    normalized_text = _normalize_alias(combined_text)
    if not normalized_text:
        return None

    for alias, ticker in _cache.corp_aliases:
        if alias and alias in normalized_text:
            return ticker
    return None


__all__ = ["resolve_news_ticker"]
